{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "venv",
   "display_name": "Python 3.9.5  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4f0ffb3683f6d916fbba459b0ddb22e5e675b5ce53403c30e65bad3b886ae6df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Defining the visual vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from vocabulary import Vocabulary, open_image, draw_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join('..', 'data')\n",
    "n_words = 100\n",
    "\n",
    "print(f'Creating vocabulary with {n_words} words')\n",
    "sys.stdout.flush()\n",
    "vocabulary = Vocabulary(n_words)\n",
    "\n",
    "# Get relative paths for the images on the dataset directory\n",
    "images = [os.path.join(dataset_dir, image) for image in sorted(os.listdir(dataset_dir))]\n",
    "images = images[:500]\n",
    "\n",
    "# Find keypoints for the vocabulary\n",
    "vocabulary.train(images)\n",
    "\n",
    "print(f'Vocabulary dimensions: {len(vocabulary.vocabulary.shape)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw keypoints for the first image\n",
    "query_image = images[0]\n",
    "\n",
    "print('Processing first image...')\n",
    "img_a = open_image(query_image)\n",
    "if img_a is not None:\n",
    "    detector = cv.BRISK_create()\n",
    "    k, d = detector.detectAndCompute(img_a, None)\n",
    "    words = []\n",
    "    for i in range(d.shape[0]):\n",
    "        words.append(vocabulary.which_word(d[i, :]))\n",
    "    draw_keypoints('imageA', img_a, k, words)"
   ]
  },
  {
   "source": [
    "# Training the Bag of Words vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform Vector Quantization to represent the histogram of features as a vector\n",
    "# Vector Quantization assigns codes from a code book to observations\n",
    "from scipy.cluster.vq import vq\n",
    "\n",
    "img_features = np.zeros((len(images), n_words), 'float32')\n",
    "for i in range(len(images)):\n",
    "    words, distance = vq(vocabulary.descriptor_list[i][1], vocabulary.vocabulary)\n",
    "    for word in words:\n",
    "        img_features[i][word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Tf-Idf Vectorization\n",
    "n_occurences = np.sum((img_features > 0) * 1, axis=0)\n",
    "idf = np.array(np.log((1.0 * len(images) + 1) / (1.0 * n_occurences + 1)), 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the words (normalization)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(img_features)\n",
    "img_features = scaler.transform(img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define classes for each image\n",
    "img_class = []\n",
    "with open('multiclass.csv') as img_classes:\n",
    "    img_class = sorted(map(lambda line: line.strip().split(','), img_classes.readlines()))\n",
    "\n",
    "classes = [data[1] for data in img_class]\n",
    "classes = classes[:500]\n",
    "print(classes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Support Vector Classification model to discriminate vectors\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(max_iter=50000) # 50000 iterations for better odds of converging\n",
    "svc.fit(img_features, np.array(classes))"
   ]
  },
  {
   "source": [
    "# Validating Bag of Words model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}